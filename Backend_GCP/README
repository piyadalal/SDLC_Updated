Setup Guide for Mac M1:
pip install google-cloud-aiplatform
#brew install --cask google-cloud-sdk
pip install protobuf==3.20.3
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
gcloud auth login
gcloud config set project uk-labs-hackathon-1-0625-dev
Using Gemini 1.5 Pro which is a managed, pre-deployed model hosted by Google on Vertex AI.
You just call it directly via the SDK or API using its model name ("gemini-1.5-pro-preview").
Google handles the deployment, scaling, and infrastructure for you behind the scenes.
So the workflow is:
Initialize your Vertex AI client with your project and region.
Reference the pre-deployed model by name.
Send prompts and get responses â€” no deployment step needed on your end.
When would you deploy a model yourself?
If you trained a custom model (e.g., your own TensorFlow or PyTorch model).
Or if you want to deploy a custom container for inference.



Avoiding pulling conflicting files remote to local :
 add to gitignore
 vi .idea/.gitignore
__pycache__/
*.pyc

remove tracked file : git rm --cached ForgeApp/__pycache__/excel_formatter.cpython-313.pyc
git commit -m "Remove __pycache__ from repo"